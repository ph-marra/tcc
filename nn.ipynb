{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b28df108-25d0-478f-b4dc-f516c639539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 SUPER'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "users = pd.read_csv(\"dados_para_correlacoes_juntos_por_temp.csv\")\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98ee5ffc-e279-4732-a778-1579a28c847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>qtd_posts</th>\n",
       "      <th>media_likes</th>\n",
       "      <th>qtd_posts_positivos</th>\n",
       "      <th>qtd_posts_negativos</th>\n",
       "      <th>qtd_posts_neutros</th>\n",
       "      <th>qtd_posts_possui_emoticon</th>\n",
       "      <th>seguidores</th>\n",
       "      <th>seguidos</th>\n",
       "      <th>proporcao_final_semana</th>\n",
       "      <th>proporcao_meio_semana</th>\n",
       "      <th>proporcao_manha</th>\n",
       "      <th>proporcao_tarde</th>\n",
       "      <th>proporcao_noite</th>\n",
       "      <th>proporcao_madrugada</th>\n",
       "      <th>temperamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>176.142857</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1220</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>176.142857</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1220</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1036</td>\n",
       "      <td>49</td>\n",
       "      <td>191.061224</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>1805</td>\n",
       "      <td>919</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1036</td>\n",
       "      <td>49</td>\n",
       "      <td>191.061224</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>1805</td>\n",
       "      <td>919</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.6939</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>worrying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1037</td>\n",
       "      <td>2</td>\n",
       "      <td>57.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>175</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1038</td>\n",
       "      <td>13</td>\n",
       "      <td>72.384615</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>508</td>\n",
       "      <td>514</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1040</td>\n",
       "      <td>59</td>\n",
       "      <td>220.491525</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>1075</td>\n",
       "      <td>1356</td>\n",
       "      <td>0.4915</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  qtd_posts  media_likes  qtd_posts_positivos  \\\n",
       "0          8          7   176.142857                    6   \n",
       "1          8          7   176.142857                    6   \n",
       "2         10          5     9.000000                    3   \n",
       "3         10          5     9.000000                    3   \n",
       "4         10          5     9.000000                    3   \n",
       "..       ...        ...          ...                  ...   \n",
       "239     1036         49   191.061224                   40   \n",
       "240     1036         49   191.061224                   40   \n",
       "241     1037          2    57.500000                    2   \n",
       "242     1038         13    72.384615                   10   \n",
       "243     1040         59   220.491525                   55   \n",
       "\n",
       "     qtd_posts_negativos  qtd_posts_neutros  qtd_posts_possui_emoticon  \\\n",
       "0                      0                  1                          7   \n",
       "1                      0                  1                          7   \n",
       "2                      0                  2                          2   \n",
       "3                      0                  2                          2   \n",
       "4                      0                  2                          2   \n",
       "..                   ...                ...                        ...   \n",
       "239                    0                  9                         24   \n",
       "240                    0                  9                         24   \n",
       "241                    0                  0                          1   \n",
       "242                    0                  3                         10   \n",
       "243                    0                  4                         59   \n",
       "\n",
       "     seguidores  seguidos  proporcao_final_semana  proporcao_meio_semana  \\\n",
       "0          1220      1108                  0.4286                 0.5714   \n",
       "1          1220      1108                  0.4286                 0.5714   \n",
       "2            49        60                  0.2000                 0.8000   \n",
       "3            49        60                  0.2000                 0.8000   \n",
       "4            49        60                  0.2000                 0.8000   \n",
       "..          ...       ...                     ...                    ...   \n",
       "239        1805       919                  0.3061                 0.6939   \n",
       "240        1805       919                  0.3061                 0.6939   \n",
       "241         342       175                  0.5000                 0.5000   \n",
       "242         508       514                  0.6154                 0.3846   \n",
       "243        1075      1356                  0.4915                 0.5085   \n",
       "\n",
       "     proporcao_manha  proporcao_tarde  proporcao_noite  proporcao_madrugada  \\\n",
       "0             0.1429           0.4286           0.4286               0.0000   \n",
       "1             0.1429           0.4286           0.4286               0.0000   \n",
       "2             0.2000           0.4000           0.2000               0.2000   \n",
       "3             0.2000           0.4000           0.2000               0.2000   \n",
       "4             0.2000           0.4000           0.2000               0.2000   \n",
       "..               ...              ...              ...                  ...   \n",
       "239           0.0204           0.2857           0.5714               0.1224   \n",
       "240           0.0204           0.2857           0.5714               0.1224   \n",
       "241           0.0000           0.5000           0.5000               0.0000   \n",
       "242           0.0769           0.1538           0.6154               0.1538   \n",
       "243           0.0000           0.1525           0.6441               0.2034   \n",
       "\n",
       "    temperamento  \n",
       "0        anxious  \n",
       "1     depressive  \n",
       "2        anxious  \n",
       "3    cyclothymic  \n",
       "4     depressive  \n",
       "..           ...  \n",
       "239    irritable  \n",
       "240     worrying  \n",
       "241    irritable  \n",
       "242   depressive  \n",
       "243   depressive  \n",
       "\n",
       "[244 rows x 16 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d1796587-0e3e-4199-acb3-7094e3aac43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2000e+01, 3.0298e+02, 8.0000e+01,  ..., 2.6090e-01, 5.0000e-01,\n",
       "         1.0900e-02],\n",
       "        [1.4000e+01, 5.5521e+02, 1.3000e+01,  ..., 0.0000e+00, 2.8570e-01,\n",
       "         6.4290e-01],\n",
       "        [2.3000e+01, 1.6439e+02, 1.8000e+01,  ..., 3.9130e-01, 3.4780e-01,\n",
       "         4.3500e-02],\n",
       "        ...,\n",
       "        [9.2000e+01, 3.0298e+02, 8.0000e+01,  ..., 2.6090e-01, 5.0000e-01,\n",
       "         1.0900e-02],\n",
       "        [1.4000e+01, 7.1714e+01, 6.0000e+00,  ..., 2.8570e-01, 3.5710e-01,\n",
       "         1.4290e-01],\n",
       "        [9.0000e+00, 8.9778e+01, 8.0000e+00,  ..., 0.0000e+00, 7.7780e-01,\n",
       "         2.2220e-01]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8 * len(users))\n",
    "test_size = len(users) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(users, [train_size, test_size])\n",
    "\n",
    "train_dataset = train_dataset.dataset.iloc[train_dataset.indices].drop(axis=1, columns=['user_id'])\n",
    "\n",
    "train_target = train_dataset.pop('temperamento')\n",
    "test_dataset = test_dataset.dataset.iloc[test_dataset.indices].drop(axis=1, columns=['user_id'])\n",
    "test_target = test_dataset.pop('temperamento')\n",
    "test_tensor = torch.Tensor(test_dataset.values).type(torch.FloatTensor)\n",
    "\n",
    "train_tensor = torch.Tensor(train_dataset.values).type(torch.FloatTensor)#.to('cuda')\n",
    "train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "770e75f9-6d95-48c4-b6d2-64d5d1b2611f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9000e+01, 8.9789e+01, 1.2000e+01, 0.0000e+00, 7.0000e+00, 1.7000e+01,\n",
       "         8.2800e+02, 3.7400e+02, 3.6840e-01, 6.3160e-01, 3.1580e-01, 2.6320e-01,\n",
       "         3.6840e-01, 5.2600e-02],\n",
       "        [1.4000e+01, 2.6929e+01, 1.2000e+01, 0.0000e+00, 2.0000e+00, 1.3000e+01,\n",
       "         3.7100e+02, 2.0050e+03, 7.1400e-02, 9.2860e-01, 3.5710e-01, 2.8570e-01,\n",
       "         1.4290e-01, 2.1430e-01],\n",
       "        [4.0000e+00, 1.1150e+02, 3.0000e+00, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
       "         1.0800e+03, 6.0300e+02, 2.5000e-01, 7.5000e-01, 5.0000e-01, 2.5000e-01,\n",
       "         2.5000e-01, 0.0000e+00],\n",
       "        [1.4000e+01, 5.5521e+02, 1.3000e+01, 0.0000e+00, 1.0000e+00, 1.1000e+01,\n",
       "         1.7000e+03, 1.0370e+03, 2.1430e-01, 7.8570e-01, 7.1400e-02, 0.0000e+00,\n",
       "         2.8570e-01, 6.4290e-01],\n",
       "        [1.4000e+01, 1.1457e+02, 1.2000e+01, 0.0000e+00, 2.0000e+00, 1.0000e+01,\n",
       "         4.8800e+02, 9.8000e+02, 2.8570e-01, 7.1430e-01, 3.5710e-01, 2.8570e-01,\n",
       "         2.8570e-01, 7.1400e-02],\n",
       "        [2.1000e+01, 1.0138e+02, 1.8000e+01, 0.0000e+00, 3.0000e+00, 1.2000e+01,\n",
       "         1.2600e+03, 1.6450e+03, 4.7620e-01, 5.2380e-01, 0.0000e+00, 9.5200e-02,\n",
       "         3.8100e-01, 5.2380e-01],\n",
       "        [5.2000e+01, 1.0198e+02, 4.7000e+01, 0.0000e+00, 5.0000e+00, 3.8000e+01,\n",
       "         1.0490e+03, 4.0700e+02, 4.8080e-01, 5.1920e-01, 0.0000e+00, 1.1540e-01,\n",
       "         7.5000e-01, 1.3460e-01],\n",
       "        [4.0000e+00, 1.1150e+02, 3.0000e+00, 1.0000e+00, 0.0000e+00, 2.0000e+00,\n",
       "         1.0800e+03, 6.0300e+02, 2.5000e-01, 7.5000e-01, 5.0000e-01, 2.5000e-01,\n",
       "         2.5000e-01, 0.0000e+00],\n",
       "        [2.1000e+01, 6.1095e+01, 1.2000e+01, 0.0000e+00, 9.0000e+00, 9.0000e+00,\n",
       "         3.8500e+02, 5.6100e+02, 2.8570e-01, 7.1430e-01, 2.8570e-01, 3.3330e-01,\n",
       "         2.8570e-01, 9.5200e-02],\n",
       "        [1.0100e+02, 2.0733e+01, 8.6000e+01, 0.0000e+00, 1.5000e+01, 0.0000e+00,\n",
       "         1.0270e+03, 8.8500e+02, 4.6530e-01, 5.3470e-01, 1.9800e-02, 2.5740e-01,\n",
       "         4.0590e-01, 3.1680e-01],\n",
       "        [1.0000e+00, 5.5000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         2.6100e+02, 3.1600e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [1.9000e+01, 8.9789e+01, 1.2000e+01, 0.0000e+00, 7.0000e+00, 1.7000e+01,\n",
       "         8.2800e+02, 3.7400e+02, 3.6840e-01, 6.3160e-01, 3.1580e-01, 2.6320e-01,\n",
       "         3.6840e-01, 5.2600e-02],\n",
       "        [1.0000e+01, 1.0970e+02, 8.0000e+00, 0.0000e+00, 2.0000e+00, 7.0000e+00,\n",
       "         8.3800e+02, 8.3900e+02, 2.0000e-01, 8.0000e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [1.0100e+02, 2.0733e+01, 8.6000e+01, 0.0000e+00, 1.5000e+01, 0.0000e+00,\n",
       "         1.0270e+03, 8.8500e+02, 4.6530e-01, 5.3470e-01, 1.9800e-02, 2.5740e-01,\n",
       "         4.0590e-01, 3.1680e-01],\n",
       "        [4.4000e+01, 2.9886e+01, 4.3000e+01, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         2.0700e+02, 5.2400e+02, 2.2730e-01, 7.7270e-01, 1.3640e-01, 4.7730e-01,\n",
       "         2.9550e-01, 9.0900e-02],\n",
       "        [4.9000e+01, 1.9106e+02, 4.0000e+01, 0.0000e+00, 9.0000e+00, 2.4000e+01,\n",
       "         1.8050e+03, 9.1900e+02, 3.0610e-01, 6.9390e-01, 2.0400e-02, 2.8570e-01,\n",
       "         5.7140e-01, 1.2240e-01],\n",
       "        [5.2000e+01, 1.0198e+02, 4.7000e+01, 0.0000e+00, 5.0000e+00, 3.8000e+01,\n",
       "         1.0490e+03, 4.0700e+02, 4.8080e-01, 5.1920e-01, 0.0000e+00, 1.1540e-01,\n",
       "         7.5000e-01, 1.3460e-01],\n",
       "        [3.0000e+00, 1.6667e+01, 3.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         1.2700e+02, 5.9000e+02, 6.6670e-01, 3.3330e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.6670e-01, 3.3330e-01],\n",
       "        [1.5000e+01, 1.8200e+01, 1.4000e+01, 0.0000e+00, 1.0000e+00, 3.0000e+00,\n",
       "         1.1800e+02, 1.4400e+02, 2.0000e-01, 8.0000e-01, 6.6700e-02, 3.3330e-01,\n",
       "         4.0000e-01, 2.0000e-01],\n",
       "        [1.8340e+03, 6.2604e+01, 1.5870e+03, 0.0000e+00, 2.4700e+02, 5.4900e+02,\n",
       "         3.8980e+03, 7.4330e+03, 2.6340e-01, 7.3660e-01, 5.5100e-02, 2.9990e-01,\n",
       "         2.7590e-01, 3.6910e-01],\n",
       "        [6.0000e+00, 3.3500e+01, 1.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00,\n",
       "         5.4500e+02, 7.5200e+02, 5.0000e-01, 5.0000e-01, 1.6670e-01, 1.6670e-01,\n",
       "         3.3330e-01, 3.3330e-01],\n",
       "        [5.9000e+01, 2.2049e+02, 5.5000e+01, 0.0000e+00, 4.0000e+00, 5.9000e+01,\n",
       "         1.0750e+03, 1.3560e+03, 4.9150e-01, 5.0850e-01, 0.0000e+00, 1.5250e-01,\n",
       "         6.4410e-01, 2.0340e-01],\n",
       "        [2.2000e+01, 1.3205e+02, 1.5000e+01, 1.0000e+00, 6.0000e+00, 1.8000e+01,\n",
       "         8.7200e+02, 8.4500e+02, 4.0910e-01, 5.9090e-01, 3.6360e-01, 4.5500e-02,\n",
       "         5.4550e-01, 4.5500e-02],\n",
       "        [8.0000e+00, 5.4500e+01, 6.0000e+00, 1.0000e+00, 1.0000e+00, 7.0000e+00,\n",
       "         3.3800e+02, 3.5600e+02, 3.7500e-01, 6.2500e-01, 1.2500e-01, 0.0000e+00,\n",
       "         8.7500e-01, 0.0000e+00],\n",
       "        [1.0000e+00, 7.0000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         9.1800e+02, 5.1200e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 3.9800e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.1540e+03, 7.3100e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [1.5000e+01, 1.8200e+01, 1.4000e+01, 0.0000e+00, 1.0000e+00, 3.0000e+00,\n",
       "         1.1800e+02, 1.4400e+02, 2.0000e-01, 8.0000e-01, 6.6700e-02, 3.3330e-01,\n",
       "         4.0000e-01, 2.0000e-01],\n",
       "        [2.4000e+01, 8.5250e+01, 1.8000e+01, 0.0000e+00, 6.0000e+00, 1.7000e+01,\n",
       "         1.4470e+03, 1.1570e+03, 3.7500e-01, 6.2500e-01, 1.2500e-01, 4.5830e-01,\n",
       "         4.1670e-01, 0.0000e+00],\n",
       "        [2.2000e+01, 1.3205e+02, 1.5000e+01, 1.0000e+00, 6.0000e+00, 1.8000e+01,\n",
       "         8.7200e+02, 8.4500e+02, 4.0910e-01, 5.9090e-01, 3.6360e-01, 4.5500e-02,\n",
       "         5.4550e-01, 4.5500e-02],\n",
       "        [1.0000e+00, 7.0000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         9.1800e+02, 5.1200e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 2.9000e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         9.2900e+02, 6.3500e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [2.5000e+01, 2.2208e+02, 2.3000e+01, 0.0000e+00, 2.0000e+00, 2.3000e+01,\n",
       "         2.4520e+03, 1.1760e+03, 4.4000e-01, 5.6000e-01, 1.2000e-01, 1.6000e-01,\n",
       "         6.0000e-01, 1.2000e-01],\n",
       "        [6.0000e+00, 1.0917e+02, 4.0000e+00, 0.0000e+00, 2.0000e+00, 1.0000e+00,\n",
       "         5.8500e+02, 2.5800e+02, 0.0000e+00, 1.0000e+00, 5.0000e-01, 3.3330e-01,\n",
       "         1.6670e-01, 0.0000e+00],\n",
       "        [4.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         7.6900e+02, 1.4070e+03, 2.5000e-01, 7.5000e-01, 0.0000e+00, 5.0000e-01,\n",
       "         2.5000e-01, 2.5000e-01],\n",
       "        [1.0000e+00, 2.9000e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         9.2900e+02, 6.3500e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [4.0000e+00, 4.7750e+01, 3.0000e+00, 0.0000e+00, 1.0000e+00, 3.0000e+00,\n",
       "         5.5700e+02, 1.2190e+03, 2.5000e-01, 7.5000e-01, 2.5000e-01, 2.5000e-01,\n",
       "         2.5000e-01, 2.5000e-01],\n",
       "        [2.1000e+01, 1.3262e+02, 2.0000e+01, 0.0000e+00, 1.0000e+00, 2.0000e+01,\n",
       "         1.3850e+03, 1.2530e+03, 3.8100e-01, 6.1900e-01, 9.5200e-02, 2.3810e-01,\n",
       "         6.6670e-01, 0.0000e+00],\n",
       "        [1.4000e+01, 5.5521e+02, 1.3000e+01, 0.0000e+00, 1.0000e+00, 1.1000e+01,\n",
       "         1.7000e+03, 1.0370e+03, 2.1430e-01, 7.8570e-01, 7.1400e-02, 0.0000e+00,\n",
       "         2.8570e-01, 6.4290e-01],\n",
       "        [8.0000e+00, 1.6250e+02, 5.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "         9.0700e+02, 1.0580e+03, 3.7500e-01, 6.2500e-01, 1.2500e-01, 1.2500e-01,\n",
       "         6.2500e-01, 1.2500e-01],\n",
       "        [4.0000e+00, 8.3500e+01, 3.0000e+00, 0.0000e+00, 1.0000e+00, 2.0000e+00,\n",
       "         6.0200e+02, 2.8900e+02, 5.0000e-01, 5.0000e-01, 0.0000e+00, 0.0000e+00,\n",
       "         2.5000e-01, 7.5000e-01],\n",
       "        [2.4000e+01, 8.5250e+01, 1.8000e+01, 0.0000e+00, 6.0000e+00, 1.7000e+01,\n",
       "         1.4470e+03, 1.1570e+03, 3.7500e-01, 6.2500e-01, 1.2500e-01, 4.5830e-01,\n",
       "         4.1670e-01, 0.0000e+00],\n",
       "        [5.0000e+00, 9.0000e+00, 3.0000e+00, 0.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "         4.9000e+01, 6.0000e+01, 2.0000e-01, 8.0000e-01, 2.0000e-01, 4.0000e-01,\n",
       "         2.0000e-01, 2.0000e-01],\n",
       "        [1.0100e+02, 2.0733e+01, 8.6000e+01, 0.0000e+00, 1.5000e+01, 0.0000e+00,\n",
       "         1.0270e+03, 8.8500e+02, 4.6530e-01, 5.3470e-01, 1.9800e-02, 2.5740e-01,\n",
       "         4.0590e-01, 3.1680e-01],\n",
       "        [1.0000e+01, 1.0970e+02, 8.0000e+00, 0.0000e+00, 2.0000e+00, 7.0000e+00,\n",
       "         8.3800e+02, 8.3900e+02, 2.0000e-01, 8.0000e-01, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [9.0000e+00, 8.9778e+01, 8.0000e+00, 0.0000e+00, 1.0000e+00, 3.0000e+00,\n",
       "         5.6300e+02, 6.7200e+02, 3.3330e-01, 6.6670e-01, 0.0000e+00, 0.0000e+00,\n",
       "         7.7780e-01, 2.2220e-01],\n",
       "        [3.0000e+00, 1.1933e+02, 1.0000e+00, 0.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "         1.0750e+03, 6.2100e+02, 3.3330e-01, 6.6670e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.6670e-01, 3.3330e-01],\n",
       "        [1.0000e+00, 3.9800e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.1540e+03, 7.3100e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00],\n",
       "        [8.0000e+00, 1.6250e+02, 5.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "         9.0700e+02, 1.0580e+03, 3.7500e-01, 6.2500e-01, 1.2500e-01, 1.2500e-01,\n",
       "         6.2500e-01, 1.2500e-01],\n",
       "        [1.4000e+01, 5.5521e+02, 1.3000e+01, 0.0000e+00, 1.0000e+00, 1.1000e+01,\n",
       "         1.7000e+03, 1.0370e+03, 2.1430e-01, 7.8570e-01, 7.1400e-02, 0.0000e+00,\n",
       "         2.8570e-01, 6.4290e-01]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1e70e410-f637-4e27-ae7c-03f0bf846ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53     hyperthymic\n",
       "92     cyclothymic\n",
       "197       worrying\n",
       "106      irritable\n",
       "176     depressive\n",
       "190     depressive\n",
       "128      irritable\n",
       "183      irritable\n",
       "173      irritable\n",
       "2          anxious\n",
       "11      depressive\n",
       "83      depressive\n",
       "82     cyclothymic\n",
       "64       irritable\n",
       "221     depressive\n",
       "75         anxious\n",
       "49      depressive\n",
       "198      irritable\n",
       "202    hyperthymic\n",
       "155      irritable\n",
       "224       worrying\n",
       "185     depressive\n",
       "189     depressive\n",
       "213        anxious\n",
       "22      depressive\n",
       "127    hyperthymic\n",
       "178     depressive\n",
       "158    cyclothymic\n",
       "26     hyperthymic\n",
       "47       irritable\n",
       "131    cyclothymic\n",
       "191     depressive\n",
       "199        anxious\n",
       "181     depressive\n",
       "167      irritable\n",
       "182    hyperthymic\n",
       "120     depressive\n",
       "225     depressive\n",
       "149      irritable\n",
       "31      depressive\n",
       "9       depressive\n",
       "18       irritable\n",
       "216    hyperthymic\n",
       "161      irritable\n",
       "147     depressive\n",
       "5      hyperthymic\n",
       "86        worrying\n",
       "180    cyclothymic\n",
       "110      irritable\n",
       "Name: temperamento, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47709aba-728c-4e84-80b3-b9f8c93522e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161      irritable\n",
       "192        anxious\n",
       "124        anxious\n",
       "96        worrying\n",
       "193    cyclothymic\n",
       "          ...     \n",
       "105    hyperthymic\n",
       "139        anxious\n",
       "50         anxious\n",
       "205     depressive\n",
       "8      cyclothymic\n",
       "Name: temperamento, Length: 195, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ab927b-0706-49e7-aa0a-1813e38cdcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['irritable', 'anxious', 'worrying', 'cyclothymic', 'depressive',\n",
       "       'hyperthymic'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "471d6f16-e03a-465f-bd35-14a7de6aa93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_target_tensor = train_target.map({'worrying': 1,\n",
    "#                                         'depressive': 2,\n",
    "#                                         'cyclothymic': 3,\n",
    "#                                         'hyperthymic': 4,\n",
    "#                                         'irritable': 5,\n",
    "#                                         'anxious': 6})\n",
    "\n",
    "\n",
    "\n",
    "train_target_tensor = list(train_target.map({'worrying': [1, 0, 0, 0, 0, 0],\n",
    "                                        'depressive': [0, 1, 0, 0, 0, 0],\n",
    "                                        'cyclothymic': [0, 0, 1, 0, 0, 0],\n",
    "                                        'hyperthymic': [0, 0, 0, 1, 0, 0],\n",
    "                                        'irritable': [0, 0, 0, 0, 1, 0],\n",
    "                                        'anxious': [0, 0, 0, 0, 0, 1]}))\n",
    "\n",
    "train_target_tensor = torch.Tensor(train_target_tensor)#.float()#.to('cuda')\n",
    "train_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b5612c3-005a-4535-879f-546bc4a25a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperaments = len(train_target.unique())\n",
    "temperaments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "97c728a4-473f-48d4-baab-4832e18732d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(14, 28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28, 56),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(56, 56),\n",
    "    torch.nn.ReLU(),\n",
    "    # torch.nn.Linear(56, 56),\n",
    "    # torch.nn.ReLU(),\n",
    "    torch.nn.Linear(56, 28),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(28, 14),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(14, 6),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")#.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f65c508c-6519-4b99-89be-7414c2df8128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0991, 0.1300, 0.2524, 0.1819, 0.1546, 0.1821],\n",
       "        [0.0073, 0.0095, 0.3739, 0.0530, 0.1153, 0.4410],\n",
       "        [0.0060, 0.0066, 0.4802, 0.0497, 0.0903, 0.3673],\n",
       "        ...,\n",
       "        [0.0063, 0.0057, 0.5568, 0.0984, 0.0547, 0.2781],\n",
       "        [0.0433, 0.0040, 0.2022, 0.3790, 0.0131, 0.3585],\n",
       "        [0.1027, 0.1002, 0.2576, 0.1983, 0.1349, 0.2063]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(train_tensor)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "225d0971-ccd5-4edd-a37d-7bdedd4d881c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7768e-03, 2.4974e-01, 2.3847e-01, 3.7841e-16, 2.5800e-01, 2.5202e-01],\n",
       "        [2.5383e-01, 2.5531e-01, 2.4576e-01, 0.0000e+00, 1.2103e-12, 2.4511e-01],\n",
       "        [1.4324e-13, 2.5430e-01, 2.4117e-01, 0.0000e+00, 2.3844e-01, 2.6609e-01],\n",
       "        ...,\n",
       "        [4.7637e-21, 2.5640e-01, 2.5013e-01, 0.0000e+00, 2.4076e-01, 2.5271e-01],\n",
       "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [4.0602e-06, 3.3519e-01, 3.3190e-01, 1.7468e-33, 3.3287e-01, 3.3587e-05]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# loss = loss_fn(output, label)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 10000\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(train_tensor)\n",
    "    loss = loss_fn(y_pred, train_target_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "23cbd623-1686-4535-9597-ec16700dad80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.776758e-03</td>\n",
       "      <td>0.249735</td>\n",
       "      <td>2.384682e-01</td>\n",
       "      <td>3.784146e-16</td>\n",
       "      <td>2.580022e-01</td>\n",
       "      <td>2.520176e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.538289e-01</td>\n",
       "      <td>0.255306</td>\n",
       "      <td>2.457574e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.210252e-12</td>\n",
       "      <td>2.451074e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.432401e-13</td>\n",
       "      <td>0.254297</td>\n",
       "      <td>2.411680e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.384420e-01</td>\n",
       "      <td>2.660930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.514071e-07</td>\n",
       "      <td>0.354493</td>\n",
       "      <td>3.464280e-01</td>\n",
       "      <td>3.657389e-42</td>\n",
       "      <td>3.179622e-03</td>\n",
       "      <td>2.958997e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.538289e-01</td>\n",
       "      <td>0.255306</td>\n",
       "      <td>2.457574e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.210252e-12</td>\n",
       "      <td>2.451074e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2.974705e-38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.681674e-30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.929106e-34</td>\n",
       "      <td>6.956319e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.759232e-05</td>\n",
       "      <td>0.339720</td>\n",
       "      <td>3.309726e-01</td>\n",
       "      <td>2.826419e-42</td>\n",
       "      <td>2.531992e-05</td>\n",
       "      <td>3.292641e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.763694e-21</td>\n",
       "      <td>0.256405</td>\n",
       "      <td>2.501261e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.407551e-01</td>\n",
       "      <td>2.527139e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4.060182e-06</td>\n",
       "      <td>0.335194</td>\n",
       "      <td>3.318971e-01</td>\n",
       "      <td>1.746836e-33</td>\n",
       "      <td>3.328708e-01</td>\n",
       "      <td>3.358738e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1             2             3             4  \\\n",
       "0    1.776758e-03  0.249735  2.384682e-01  3.784146e-16  2.580022e-01   \n",
       "1    2.538289e-01  0.255306  2.457574e-01  0.000000e+00  1.210252e-12   \n",
       "2    1.432401e-13  0.254297  2.411680e-01  0.000000e+00  2.384420e-01   \n",
       "3    1.514071e-07  0.354493  3.464280e-01  3.657389e-42  3.179622e-03   \n",
       "4    2.538289e-01  0.255306  2.457574e-01  0.000000e+00  1.210252e-12   \n",
       "..            ...       ...           ...           ...           ...   \n",
       "190  2.974705e-38  1.000000  3.681674e-30  0.000000e+00  2.929106e-34   \n",
       "191  1.759232e-05  0.339720  3.309726e-01  2.826419e-42  2.531992e-05   \n",
       "192  4.763694e-21  0.256405  2.501261e-01  0.000000e+00  2.407551e-01   \n",
       "193  0.000000e+00  1.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "194  4.060182e-06  0.335194  3.318971e-01  1.746836e-33  3.328708e-01   \n",
       "\n",
       "                5  \n",
       "0    2.520176e-01  \n",
       "1    2.451074e-01  \n",
       "2    2.660930e-01  \n",
       "3    2.958997e-01  \n",
       "4    2.451074e-01  \n",
       "..            ...  \n",
       "190  6.956319e-32  \n",
       "191  3.292641e-01  \n",
       "192  2.527139e-01  \n",
       "193  0.000000e+00  \n",
       "194  3.358738e-05  \n",
       "\n",
       "[195 rows x 6 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c786093-e38e-4b73-8766-382cea0ff1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 1, 5, 1, 1, 1, 5, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 5, 1, 1, 1, 4, 5, 1, 1, 5, 1, 1,\n",
       "        2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 2, 1, 1, 4, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1,\n",
       "        1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1,\n",
       "        1, 1, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(y_pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed6e5960-6255-475b-9aa3-a67b1a7256de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161      irritable\n",
       "192        anxious\n",
       "124        anxious\n",
       "96        worrying\n",
       "193    cyclothymic\n",
       "          ...     \n",
       "105    hyperthymic\n",
       "139        anxious\n",
       "50         anxious\n",
       "205     depressive\n",
       "8      cyclothymic\n",
       "Name: temperamento, Length: 195, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c84bb016-9b97-4ea6-b871-25de7fa3d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142    hyperthymic\n",
       "152    cyclothymic\n",
       "126     depressive\n",
       "222    hyperthymic\n",
       "57      depressive\n",
       "227     depressive\n",
       "193    cyclothymic\n",
       "124        anxious\n",
       "39     hyperthymic\n",
       "172    hyperthymic\n",
       "97      depressive\n",
       "139        anxious\n",
       "168       worrying\n",
       "171     depressive\n",
       "178     depressive\n",
       "239      irritable\n",
       "197       worrying\n",
       "188     depressive\n",
       "158    cyclothymic\n",
       "212     depressive\n",
       "59      depressive\n",
       "243     depressive\n",
       "50         anxious\n",
       "96        worrying\n",
       "134      irritable\n",
       "111     depressive\n",
       "157        anxious\n",
       "69         anxious\n",
       "55        worrying\n",
       "135       worrying\n",
       "78     hyperthymic\n",
       "29      depressive\n",
       "120     depressive\n",
       "207     depressive\n",
       "75         anxious\n",
       "28        worrying\n",
       "87      depressive\n",
       "224       worrying\n",
       "89      depressive\n",
       "218       worrying\n",
       "71      depressive\n",
       "3      cyclothymic\n",
       "173      irritable\n",
       "165     depressive\n",
       "201     depressive\n",
       "230    cyclothymic\n",
       "112      irritable\n",
       "88     cyclothymic\n",
       "221     depressive\n",
       "Name: temperamento, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "70849f9d-ea3c-45cd-81be-81366c85bc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7224e-05, 3.2965e-01, 3.3596e-01, 2.9567e-42, 2.6201e-05, 3.3435e-01],\n",
       "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.3616e-13, 2.3956e-01, 2.4287e-01, 0.0000e+00, 2.4875e-01, 2.6882e-01],\n",
       "        [0.0000e+00, 1.0000e+00, 5.8634e-40, 0.0000e+00, 1.5380e-09, 9.4013e-29],\n",
       "        [1.4325e-39, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [2.5061e-01, 2.4743e-01, 2.5219e-01, 0.0000e+00, 1.2536e-12, 2.4978e-01],\n",
       "        [1.3616e-13, 2.3956e-01, 2.4287e-01, 0.0000e+00, 2.4875e-01, 2.6882e-01],\n",
       "        [5.6153e-20, 1.0000e+00, 8.5409e-27, 0.0000e+00, 3.0751e-39, 1.5767e-28],\n",
       "        [8.1903e-12, 1.0000e+00, 1.4324e-13, 0.0000e+00, 6.5637e-38, 5.7517e-17],\n",
       "        [3.6568e-07, 9.9998e-01, 2.2223e-05, 2.9427e-44, 2.7347e-08, 2.9800e-07],\n",
       "        [1.7224e-05, 3.2965e-01, 3.3596e-01, 2.9567e-42, 2.6201e-05, 3.3435e-01],\n",
       "        [2.5380e-15, 1.0000e+00, 2.1360e-09, 0.0000e+00, 7.1665e-24, 1.7305e-12],\n",
       "        [8.1903e-12, 1.0000e+00, 1.4324e-13, 0.0000e+00, 6.5637e-38, 5.7517e-17],\n",
       "        [1.2128e-23, 1.0000e+00, 2.2137e-34, 0.0000e+00, 0.0000e+00, 2.4782e-32],\n",
       "        [2.5014e-22, 4.9418e-05, 3.3288e-01, 0.0000e+00, 3.3544e-01, 3.3163e-01],\n",
       "        [2.5061e-01, 2.4743e-01, 2.5219e-01, 0.0000e+00, 1.2536e-12, 2.4978e-01],\n",
       "        [3.0408e-33, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.7644e-03, 2.4697e-01, 2.3921e-01, 3.8190e-16, 2.5960e-01, 2.5247e-01],\n",
       "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.5044e-28, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [3.0969e-43, 1.0000e+00, 1.1203e-37, 0.0000e+00, 0.0000e+00, 2.8895e-42],\n",
       "        [4.4876e-21, 2.4020e-01, 2.5223e-01, 0.0000e+00, 2.5177e-01, 2.5580e-01],\n",
       "        [1.4890e-07, 3.4509e-01, 3.5179e-01, 3.7891e-42, 3.2671e-03, 2.9985e-01],\n",
       "        [3.8999e-07, 3.2926e-01, 3.3656e-01, 0.0000e+00, 3.9766e-07, 3.3418e-01],\n",
       "        [0.0000e+00, 7.8729e-10, 1.6060e-28, 0.0000e+00, 1.0000e+00, 3.0886e-22],\n",
       "        [1.7644e-03, 2.4697e-01, 2.3921e-01, 3.8190e-16, 2.5960e-01, 2.5247e-01],\n",
       "        [1.4883e-05, 9.9998e-01, 1.8498e-06, 0.0000e+00, 1.2612e-44, 9.6585e-18],\n",
       "        [4.4876e-21, 2.4020e-01, 2.5223e-01, 0.0000e+00, 2.5177e-01, 2.5580e-01],\n",
       "        [3.8999e-07, 3.2926e-01, 3.3656e-01, 0.0000e+00, 3.9766e-07, 3.3418e-01],\n",
       "        [3.3355e-01, 3.2869e-01, 3.3777e-01, 0.0000e+00, 7.3390e-25, 5.1153e-07],\n",
       "        [9.4902e-16, 9.9846e-01, 1.8354e-04, 0.0000e+00, 1.0932e-19, 1.3605e-03],\n",
       "        [4.1354e-10, 1.0000e+00, 3.6704e-08, 1.3805e-40, 2.5386e-07, 1.6945e-07],\n",
       "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [3.3355e-01, 3.2869e-01, 3.3777e-01, 0.0000e+00, 7.3390e-25, 5.1153e-07],\n",
       "        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [7.0014e-17, 1.0000e+00, 4.6662e-10, 0.0000e+00, 1.0192e-37, 9.9348e-18],\n",
       "        [0.0000e+00, 1.0000e+00, 5.8634e-40, 0.0000e+00, 1.5380e-09, 9.4013e-29],\n",
       "        [8.1207e-27, 1.0000e+00, 1.6432e-21, 0.0000e+00, 1.8303e-34, 5.5874e-26],\n",
       "        [1.1609e-06, 2.4729e-01, 2.4961e-01, 3.7460e-32, 2.5090e-01, 2.5220e-01],\n",
       "        [1.4883e-05, 9.9998e-01, 1.8498e-06, 0.0000e+00, 1.2612e-44, 9.6585e-18],\n",
       "        [1.7254e-01, 2.1471e-01, 2.3211e-01, 1.0642e-07, 1.8092e-01, 1.9972e-01],\n",
       "        [8.1903e-12, 1.0000e+00, 1.4324e-13, 0.0000e+00, 6.5637e-38, 5.7517e-17],\n",
       "        [2.5380e-15, 1.0000e+00, 2.1360e-09, 0.0000e+00, 7.1665e-24, 1.7305e-12],\n",
       "        [1.3219e-18, 1.0000e+00, 2.1101e-20, 0.0000e+00, 7.7719e-32, 5.9266e-23],\n",
       "        [2.6188e-14, 2.4884e-01, 2.6331e-01, 0.0000e+00, 2.6201e-01, 2.2584e-01],\n",
       "        [0.0000e+00, 7.8729e-10, 1.6060e-28, 0.0000e+00, 1.0000e+00, 3.0886e-22],\n",
       "        [8.1207e-27, 1.0000e+00, 1.6432e-21, 0.0000e+00, 1.8303e-34, 5.5874e-26],\n",
       "        [0.0000e+00, 1.0000e+00, 5.8637e-40, 0.0000e+00, 1.5381e-09, 9.4015e-29]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1e3e1e72-4600-449c-949c-3b935f1977e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cyclothymic', 'depressive', 'anxious', 'depressive', 'depressive',\n",
       "       'depressive', 'cyclothymic', 'anxious', 'depressive', 'depressive',\n",
       "       'depressive', 'cyclothymic', 'depressive', 'depressive',\n",
       "       'depressive', 'irritable', 'cyclothymic', 'depressive',\n",
       "       'irritable', 'depressive', 'depressive', 'depressive', 'anxious',\n",
       "       'cyclothymic', 'cyclothymic', 'irritable', 'irritable',\n",
       "       'depressive', 'anxious', 'cyclothymic', 'cyclothymic',\n",
       "       'depressive', 'depressive', 'depressive', 'cyclothymic',\n",
       "       'depressive', 'depressive', 'depressive', 'depressive', 'anxious',\n",
       "       'depressive', 'cyclothymic', 'depressive', 'depressive',\n",
       "       'depressive', 'cyclothymic', 'irritable', 'depressive',\n",
       "       'depressive'], dtype='<U11')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapa = {0: 'worrying',\n",
    "        1: 'depressive',\n",
    "        2: 'cyclothymic',\n",
    "        3: 'hyperthymic',\n",
    "        4: 'irritable',\n",
    "        5: 'anxious'}\n",
    "\n",
    "r = torch.argmax(model(test_tensor), dim=1).numpy()\n",
    "new = np.array([mapa[x] for x in r])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cd119799-4a76-405a-9b03-cfb0ae241450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperamento</th>\n",
       "      <th>predito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>depressive</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>anxious</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>anxious</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>worrying</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>irritable</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>worrying</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>anxious</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>worrying</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>irritable</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>depressive</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>anxious</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>anxious</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>worrying</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>worrying</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>anxious</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worrying</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>worrying</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>worrying</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>irritable</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>irritable</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>depressive</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperamento      predito\n",
       "142  hyperthymic  cyclothymic\n",
       "152  cyclothymic   depressive\n",
       "126   depressive      anxious\n",
       "222  hyperthymic   depressive\n",
       "57    depressive   depressive\n",
       "227   depressive   depressive\n",
       "193  cyclothymic  cyclothymic\n",
       "124      anxious      anxious\n",
       "39   hyperthymic   depressive\n",
       "172  hyperthymic   depressive\n",
       "97    depressive   depressive\n",
       "139      anxious  cyclothymic\n",
       "168     worrying   depressive\n",
       "171   depressive   depressive\n",
       "178   depressive   depressive\n",
       "239    irritable    irritable\n",
       "197     worrying  cyclothymic\n",
       "188   depressive   depressive\n",
       "158  cyclothymic    irritable\n",
       "212   depressive   depressive\n",
       "59    depressive   depressive\n",
       "243   depressive   depressive\n",
       "50       anxious      anxious\n",
       "96      worrying  cyclothymic\n",
       "134    irritable  cyclothymic\n",
       "111   depressive    irritable\n",
       "157      anxious    irritable\n",
       "69       anxious   depressive\n",
       "55      worrying      anxious\n",
       "135     worrying  cyclothymic\n",
       "78   hyperthymic  cyclothymic\n",
       "29    depressive   depressive\n",
       "120   depressive   depressive\n",
       "207   depressive   depressive\n",
       "75       anxious  cyclothymic\n",
       "28      worrying   depressive\n",
       "87    depressive   depressive\n",
       "224     worrying   depressive\n",
       "89    depressive   depressive\n",
       "218     worrying      anxious\n",
       "71    depressive   depressive\n",
       "3    cyclothymic  cyclothymic\n",
       "173    irritable   depressive\n",
       "165   depressive   depressive\n",
       "201   depressive   depressive\n",
       "230  cyclothymic  cyclothymic\n",
       "112    irritable    irritable\n",
       "88   cyclothymic   depressive\n",
       "221   depressive   depressive"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.DataFrame(columns=['temperamento', 'predito'])\n",
    "resultados.temperamento = test_target\n",
    "resultados.predito = new\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "991b8c0b-9a69-4c3f-a88d-607b788e5fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperamento</th>\n",
       "      <th>predito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>depressive</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>anxious</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>worrying</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>worrying</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>worrying</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>irritable</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>depressive</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>anxious</td>\n",
       "      <td>irritable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>anxious</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>worrying</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>worrying</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>hyperthymic</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>anxious</td>\n",
       "      <td>cyclothymic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>worrying</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>worrying</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>worrying</td>\n",
       "      <td>anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>irritable</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cyclothymic</td>\n",
       "      <td>depressive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temperamento      predito\n",
       "142  hyperthymic  cyclothymic\n",
       "152  cyclothymic   depressive\n",
       "126   depressive      anxious\n",
       "222  hyperthymic   depressive\n",
       "39   hyperthymic   depressive\n",
       "172  hyperthymic   depressive\n",
       "139      anxious  cyclothymic\n",
       "168     worrying   depressive\n",
       "197     worrying  cyclothymic\n",
       "158  cyclothymic    irritable\n",
       "96      worrying  cyclothymic\n",
       "134    irritable  cyclothymic\n",
       "111   depressive    irritable\n",
       "157      anxious    irritable\n",
       "69       anxious   depressive\n",
       "55      worrying      anxious\n",
       "135     worrying  cyclothymic\n",
       "78   hyperthymic  cyclothymic\n",
       "75       anxious  cyclothymic\n",
       "28      worrying   depressive\n",
       "224     worrying   depressive\n",
       "218     worrying      anxious\n",
       "173    irritable   depressive\n",
       "88   cyclothymic   depressive"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados[resultados['temperamento'] != resultados['predito']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a21fa3d-fc27-4701-974b-fb84004405b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310141a-e603-4fa7-8e46-de5ba9a4e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142253e-1c0a-4b41-9450-1145ae8e3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e171e-de3f-4790-a1b5-30a2df33e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class MultilayerPerceptron():\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_classes):\n",
    "        super(MultilayerPerceptron, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # hidden 1\n",
    "        self.weight_1 = torch.zeros(num_hidden, num_features, \n",
    "                                    dtype=torch.float).normal_(0.0, 0.1)\n",
    "        self.bias_1 = torch.zeros(num_hidden, dtype=torch.float)\n",
    "        \n",
    "        # output\n",
    "        self.weight_o = torch.zeros(self.num_classes, num_hidden, \n",
    "                                    dtype=torch.float).normal_(0.0, 0.1)\n",
    "        self.bias_o = torch.zeros(self.num_classes, dtype=torch.float)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # hidden 1\n",
    "        \n",
    "        # input dim: [n_hidden, n_features] dot [n_features, n_examples] .T\n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        z_1 = torch.mm(x, self.weight_1.t()) + self.bias_1\n",
    "        a_1 = torch.sigmoid(z_1)\n",
    "\n",
    "        # hidden 2\n",
    "        # input dim: [n_classes, n_hidden] dot [n_hidden, n_examples] .T\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        z_2 = torch.mm(a_1, self.weight_o.t()) + self.bias_o\n",
    "        a_2 = torch.sigmoid(z_2)\n",
    "        return a_1, a_2\n",
    "\n",
    "    def backward(self, x, a_1, a_2, y):  \n",
    "    \n",
    "        #########################\n",
    "        ### Output layer weights\n",
    "        #########################\n",
    "        \n",
    "        # onehot encoding\n",
    "        y_onehot = torch.FloatTensor(y.size(0), self.num_classes)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, y.view(-1, 1).long(), 1)\n",
    "        \n",
    "\n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct * dOutAct/dOutNet * dOutNet/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "        \n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        dloss_da2 = 2.*(a_2 - y_onehot) / y.size(0)\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        da2_dz2 = a_2 * (1. - a_2) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = dloss_da2 * da2_dz2 # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        dz2__dw_out = a_1\n",
    "        \n",
    "        # input dim: [n_classlabels, n_examples] dot [n_examples, n_hidden]\n",
    "        # output dim: [n_classlabels, n_hidden]\n",
    "        dloss__dw_out = torch.mm(delta_out.t(), dz2__dw_out)\n",
    "        dloss__db_out = torch.sum(delta_out, dim=0)\n",
    "        \n",
    "\n",
    "        #################################        \n",
    "        # Part 2: dLoss/dHiddenWeights\n",
    "        ## = DeltaOut * dOutNet/dHiddenAct * dHiddenAct/dHiddenNet * dHiddenNet/dWeight\n",
    "        \n",
    "        # [n_classes, n_hidden]\n",
    "        dz2__a1 = self.weight_o\n",
    "        \n",
    "        # output dim: [n_examples, n_hidden]\n",
    "        dloss_a1 = torch.mm(delta_out, dz2__a1)\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        da1__dz1 = a_1 * (1. - a_1) # sigmoid derivative\n",
    "        \n",
    "        # [n_examples, n_features]\n",
    "        dz1__dw1 = x\n",
    "        \n",
    "        # output dim: [n_hidden, n_features]\n",
    "        dloss_dw1 = torch.mm((dloss_a1 * da1__dz1).t(), dz1__dw1)\n",
    "        dloss_db1 = torch.sum((dloss_a1 * da1__dz1), dim=0)\n",
    "\n",
    "        return dloss__dw_out, dloss__db_out, dloss_dw1, dloss_db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109773f-a365-478c-8ee8-dfa3770b68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def to_onehot(y, num_classes):\n",
    "    y_onehot = torch.FloatTensor(y.size(0), num_classes)\n",
    "    y_onehot.zero_()\n",
    "    y_onehot.scatter_(1, y.view(-1, 1).long(), 1).float()\n",
    "    return y_onehot\n",
    "\n",
    "\n",
    "def loss_func(targets_onehot, probas_onehot):\n",
    "    return torch.mean(torch.mean((targets_onehot - probas_onehot)**2, dim=0))\n",
    "\n",
    "\n",
    "def compute_mse(net, data_loader):\n",
    "    curr_mse, num_examples = torch.zeros(model.num_classes).float(), 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28)\n",
    "            logits, probas = net.forward(features)\n",
    "            y_onehot = to_onehot(targets, model.num_classes)\n",
    "            loss = torch.sum((y_onehot - probas)**2, dim=0)\n",
    "            num_examples += targets.size(0)\n",
    "            curr_mse += loss\n",
    "\n",
    "        curr_mse = torch.mean(curr_mse/num_examples, dim=0)\n",
    "        return curr_mse\n",
    "\n",
    "\n",
    "def train(model, data_loader, num_epochs,\n",
    "          learning_rate=0.1):\n",
    "    \n",
    "    minibatch_cost = []\n",
    "    epoch_cost = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "            \n",
    "            features = features.view(-1, 28*28)\n",
    "            \n",
    "            #### Compute outputs ####\n",
    "            a_1, a_2 = model.forward(features)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            dloss__dw_out, dloss__db_out, dloss_dw1, dloss_db1 = \\\n",
    "                model.backward(features, a_1, a_2, targets)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_1 -= learning_rate * dloss_dw1\n",
    "            model.bias_1 -= learning_rate * dloss_db1\n",
    "            model.weight_o -= learning_rate * dloss__dw_out\n",
    "            model.bias_o -= learning_rate * dloss__db_out\n",
    "            \n",
    "            #### Logging ####\n",
    "            curr_cost = loss_func(to_onehot(targets, model.num_classes), a_2)\n",
    "            minibatch_cost.append(curr_cost)\n",
    "            if not batch_idx % 50:\n",
    "                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                       %(e+1, NUM_EPOCHS, batch_idx, \n",
    "                         len(train_loader), curr_cost))\n",
    "        \n",
    "        #### Logging ####        \n",
    "        curr_cost = compute_mse(model, train_loader)\n",
    "        epoch_cost.append(curr_cost)\n",
    "        print('Epoch: %03d/%03d |' % (e+1, NUM_EPOCHS), end=\"\")\n",
    "        print(' Train MSE: %.5f' % curr_cost)\n",
    "\n",
    "    return minibatch_cost, epoch_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7682c-0930-408a-8fef-0729bbd225ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training \n",
    "###################################################\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = MultilayerPerceptron(num_features=28*28,\n",
    "                             num_hidden=50,\n",
    "                             num_classes=10)\n",
    "\n",
    "minibatch_cost, epoch_cost = train(model, \n",
    "                                   train_loader,\n",
    "                                   num_epochs=NUM_EPOCHS,\n",
    "                                   learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140de9d-5735-46ea-aaef-ac8aa3384b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(minibatch_cost)), minibatch_cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Minibatch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(epoch_cost)), epoch_cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c290e89-1491-4871-8e22-69398ef221cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(net, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28)\n",
    "            _, outputs = net.forward(features)\n",
    "            predicted_labels = torch.argmax(outputs, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "        return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "print('Training Accuracy: %.2f' % compute_accuracy(model, train_loader))\n",
    "print('Test Accuracy: %.2f' % compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59981cbb-1342-47f8-b4a3-5bc1cdbd6c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
